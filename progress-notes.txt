## 2026-01-26 10:07 - Task 6.1, 6.2, 6.3, 6.5, 6.6

**Status**: pending → done
**Validation**: npm run check passes (0 errors), npm run web:check passes (svelte-check 0 errors), npm test passes (736 tests, 11 API tests cover endpoints), dev server starts successfully
**Commit**: edfdfd1
**Notes**: Implemented dashboard panels with real data per specs/web-ui.md.

**Updated Dashboard (`src/web/app/src/routes/+page.svelte`):**

- Replaced all placeholder data with real API calls using `onMount`
- `Promise.all` parallel loading for:
  - `api.getStats()` → Quick stats (total nodes, tokens, cost)
  - `api.getAggregatedToolErrors()` → Tool failures by model
  - `api.listNodes()` → Recent activity timeline
  - `api.getDaemonStatus()` → Daemon/queue status
- Implemented error handling with retry-friendly message (resolved `no-ex-assign` lint issue by using separate `errorMessage` state)
- Added visual indicators for trends (improving/worsening/stable)
- Formatted metrics (percentages, currency, relative time)

**API Enhancements:**

- **Daemon Status (`src/api/routes/daemon.ts`)**:
  - Enhanced `/api/v1/daemon/status` to include queue stats (pending, running, failed)
  - Added worker stats placeholder (implicitly derived from queue state)
- **Tool Errors (`src/api/routes/tool-errors.ts`)**:
  - Updated `/api/v1/tool-errors/aggregated` to support `groupByModel=true`
  - Allows grouping by `tool, errorType` OR `model, tool, errorType`
- **Node Repository (`src/storage/node-repository.ts`)**:
  - Updated `getAggregatedToolErrors` to support optional model grouping
  - Fixed `any` type usage with proper TypeScript interface

**API Client (`src/web/app/src/lib/api/client.ts`):**

- Added `getToolErrorStats`
- Updated `getAggregatedToolErrors` signature
- Updated `getDaemonStatus` return type

**Validation:**

- Verified data flow from SQLite → Repository → API → Frontend
- Checked error states (when daemon offline)
- Verified loading states
- Verified formatting of dates and numbers

## 2026-01-26 10:47 - Task 6.4

**Status**: pending → done
**Validation**:
- Unit tests for `decision-repository` (CRUD, filtering, feedback update)
- API integration tests (ensure server starts and endpoints are registered)
- Linter checks passed
- Frontend component implemented and integrated into dashboard
**Commit**: (pending)
**Notes**: Implemented `GET /decisions` and `POST /decisions/:id/feedback` endpoints, created `DaemonDecisions` Svelte component with interactive feedback buttons, and integrated it into the main dashboard view.

## 2026-01-26 11:05 - Task 7.1, 7.2, 7.5

**Status**: pending → done
**Validation**:
- Created `extensions/brain-query.ts` implementing /brain command and brain_query tool
- Created `extensions/brain-query.test.ts` to verify registration
- Updated `tsconfig.json` and `vitest.config.ts` to include extension
- Updated `package.json` to build extension via `tsup`
- Verified build and lint (npm run build, npm run check)
- Verified tests pass (npm test)
**Commit**: [hash]
**Notes**:
- The extension code is ready but requires the backend endpoint (Task 7.3) to be fully functional.
- Implemented robust type safety and error handling.

---

## 2026-01-26 12:26 - Task 7.3

**Status**: pending → done
**Validation**:
- Created brain-query.md prompt file for natural language query answering
- Implemented query-processor.ts with node search, context gathering, and pi agent invocation
- Created /api/v1/query endpoint with POST for queries and GET /health for availability check
- Added unit tests for query processor types and API route validation
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 747 tests)
**Commit**: 4a2a194
**Notes**:
- Query processor searches knowledge graph for relevant nodes
- Gathers additional context (model quirks, tool errors) based on query keywords
- Invokes pi agent with brain-query.md prompt to synthesize answer
- Returns structured response with answer, summary, confidence, sources
- Prompt also installed to ~/.pi-brain/prompts/brain-query.md for runtime use

---

## 2026-01-26 12:41 - Task 7.4

**Status**: pending → done
**Validation**:
- Created brain skill at skills/brain/SKILL.md
- Skill follows pi skill conventions with YAML frontmatter (name, description)
- Description includes trigger keywords for agent activation
- Body provides guidance on using brain_query tool
- Includes query type examples, best practices, and when not to use
- Symlink installed to ~/skills/brain for global availability
- Added 5 unit tests for skill frontmatter validation
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 752 tests)
**Commit**: 400e4f9
**Notes**:
- Skill provides structured guidance for agents to query the knowledge graph
- Documents query types: decision lookup, error patterns, model quirks, project history, lessons, techniques
- Integrates with existing brain_query tool from brain-query extension (Task 7.1)
- Ready for end-to-end testing in Task 7.6

---

## 2026-01-26 12:53 - Task 7.6

**Status**: pending → done
**Validation**:
- Restructured brain-query extension to proper directory structure (index.ts, package.json)
- Installed extension symlink to ~/.pi/agent/extensions/brain-query
- Created 7 comprehensive integration tests in src/integration/brain-integration.test.ts
- Tests verify: node search, model quirks context, tool errors context, empty results, project filtering
- Slow tests (requiring pi agent) are skipped by default; enable with INTEGRATION_TESTS=1
- Added E2E browser test script (scripts/e2e-browser-test.sh) using agent-browser
- Added E2E testing documentation (docs/E2E-TESTING.md)
- All lint checks pass (npm run check)
- All tests pass: 755 passed, 4 skipped (npm test -- --run)
- Full integration tests pass when enabled: 7 tests passing
**Commit**: 2bf9c8e
**Notes**:
- Extension provides /brain command and brain_query tool
- Integration tests use 60s timeout for pi agent queries
- Browser E2E test can be run manually after starting dev servers
- Phase 7 (Pi Integration) is now complete

---

## 2026-01-26 13:15 - Task 8.1

**Status**: pending → done
**Validation**:
- Created scheduler.ts with Scheduler class using croner library (zero dependencies)
- Supports cron expressions from config (reanalysisSchedule, connectionDiscoverySchedule)
- Reanalysis job: queries nodes with outdated analyzer_version, queues for reprocessing
- Connection discovery job: queues recently analyzed nodes (last 7 days) for connection finding
- Manual trigger methods: triggerReanalysis(), triggerConnectionDiscovery()
- Status reporting with next run times, last results, and job state
- Validation helpers: isValidCronExpression(), getNextRunTimes()
- Added 25 comprehensive unit tests for scheduler functionality
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 780 tests, 4 skipped)
**Commit**: 48492a5
**Notes**:
- Used croner library instead of node-cron (zero dependencies, TypeScript native)
- Scheduler integrates with existing QueueManager and Database
- Exported from src/daemon/index.ts for use by daemon startup
- Ready for Task 8.2 (reanalysis queue population) to build on this

## 2026-01-26 13:45 - Task 8.2

**Status**: pending → done
**Validation**:
- Updated src/daemon/scheduler.ts to use prompt module's getLatestVersion()
- Updated runReanalysis() to query prompt_versions table instead of metadata
- Updated tests in src/daemon/scheduler.test.ts to mock prompt_versions queries
- Tests verify correct reanalysis queueing with outdated nodes
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 780 tests, 4 skipped)
**Commit**: da16fb6
**Notes**:
- Fixed issue where scheduler was querying non-existent metadata table
- Scheduler now correctly detects prompt version changes
- Ready for connection discovery tasks (8.3-8.5)


## 2026-01-26 13:45 - Task 8.2

**Status**: pending → done
**Validation**:
- Updated src/daemon/scheduler.ts to use prompt module's getLatestVersion()
- Updated runReanalysis() to query prompt_versions table instead of metadata
- Updated tests in src/daemon/scheduler.test.ts to mock prompt_versions queries
- Tests verify correct reanalysis queueing with outdated nodes
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 780 tests, 4 skipped)
**Commit**: da16fb6
**Notes**:
- Fixed issue where scheduler was querying non-existent metadata table
- Scheduler now correctly detects prompt version changes
- Ready for connection discovery tasks (8.3-8.5)


## 2026-01-26 14:02 - Task 8.3

**Status**: pending → done
**Validation**:
- Created src/daemon/connection-discovery.ts with ConnectionDiscoverer class
- Implemented hybrid similarity algorithm using Jaccard index on tags (weight 0.4), topics (weight 0.3), and summary words (weight 0.3)
- Added stopwords filtering for summary tokenization
- Updated src/daemon/worker.ts to handle 'connection_discovery' jobs using ConnectionDiscoverer (bypassing expensive LLM calls)
- Exported ConnectionDiscoverer from src/daemon/index.ts
- Added unit tests in src/daemon/connection-discovery.test.ts verifying similarity calculation and edge creation
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 787 tests)
**Commit**: [hash]
**Notes**:
- The semantic similarity approach uses a lightweight non-LLM implementation for speed and cost efficiency
- Worker now supports job types that don't require spawning a pi agent
- Ready for Task 8.4 (reference detection)

## 2026-01-26 14:30 - Task 11.1, 11.3

**Status**: pending → done
**Validation**:
- Refactored shared types to `src/types/index.ts` (Task 11.1)
- Updated backend and frontend to use shared types
- Fixed frontend type mismatches (DaemonDecisionEntity, refactoring vs refactor, edge types)
- Implemented `insertNodeToDb` and `clearAllData` in node-repository (Task 11.3)
- Implemented `rebuild-index` command in daemon CLI (Task 11.3)
- Refactored `connection-discovery.ts` to use FTS for summaries
- Verified frontend build (`npm run web:check` passes)
- Verified all unit and integration tests (`npm test -- --run` passes 24 test files)
- Verified CLI command (`./dist/cli.js daemon rebuild-index --help` works)
**Commit**: [hash]
**Notes**:
- Addressed "Shared Type Library" and "SQLite Rebuild CLI" TODOs.
- Created robust foundation for type sharing between monorepo packages.
- Added recovery mechanism for database corruption/loss via JSON rebuild.

## 2026-01-26 15:52 - Task 8.8, 8.9

**Status**: pending → done
**Validation**:
- Created 005_lesson_patterns.sql migration
- Implemented aggregateLessons() in PatternAggregator
- Updated scheduler to run all aggregations (failure patterns, model stats, lessons)
- Added unit tests for lesson aggregation and scheduler integration
- Verified clearAllData handles new tables
- All lint checks and tests pass (npm run check, npm test -- --run)
**Commit**: 8845984
**Notes**:
- Lesson aggregation groups lessons by level and exact summary text
- Scheduler now fully implements the nightly job cycle
- Ready for dashboard integration (Task 8.10)

## 2026-01-26 15:56 - Task 8.10

**Status**: pending → done
**Validation**:
- Created src/storage/pattern-repository.ts to read aggregated patterns
- Added src/api/routes/patterns.ts exposing /failures, /models, /lessons endpoints
- Added 3 unit tests for pattern-repository in src/storage/pattern-repository.test.ts
- Verified aggregated types in src/types/index.ts and src/web/app/src/lib/types.ts
- Updated Dashboard UI (src/web/app/src/routes/+page.svelte) to display:
  - Failure Patterns grid with recent examples
  - Lesson Patterns with tags
  - Model Stats (quirks/errors counts)
- Verified frontend types with npm run web:check (clean)
- Verified all backend tests with npm test -- --run (795 tests passed)
**Commit**: 4d2ca6e
**Notes**:
- The dashboard now surfaces the insights generated by the nightly jobs
- Phase 8 (Nightly Processing) is now complete
- Next: Phase 9 (Multi-Computer Sync) or Phase 10 (Prompt Learning)

---

## 2026-01-26 16:02 - Task 9.1

**Status**: pending → done
**Validation**:
- Created docs/SYNCTHING-SETUP.md with comprehensive user-facing guide
- Covers hub/spoke architecture overview with ASCII diagram
- Installation instructions for Linux and macOS
- Step-by-step setup for hub (receive folders) and spokes (share folders)
- pi-brain config.yaml spoke configuration examples
- Security best practices (receive-only, encryption, firewall)
- Troubleshooting section for common issues
- Advanced configuration (CLI, ignore patterns, bandwidth)
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 795 passed, 4 skipped)
**Commit**: 30af177
**Notes**:
- Documentation complements specs/sync-protocol.md technical spec
- Focused on practical setup rather than implementation details
- Ready for users to set up multi-computer sync with Syncthing

---

## 2026-01-26 16:17 - Task 9.2

**Status**: pending → done
**Validation**:
- Created src/sync/ module with rsync.ts, status.ts, and index.ts
- Implemented rsync execution using node:child_process execFile with promisify
- Added CLI commands: `pi-brain sync status`, `sync run`, and `sync list`
- CLI options include --spoke, --dry-run, --delete, --bwlimit, --json
- Added 26 unit tests in src/sync/sync.test.ts
- Tests cover: formatBytes, countSpokeSessionFiles, listSpokeSessions, getLastSyncTime, formatTimeAgo, getSpokeStatus, getSyncStatus, formatSyncStatus
- Created comprehensive docs/RSYNC-SETUP.md user guide
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 821 passed, 4 skipped)
**Commit**: 4daf0bb
**Notes**:
- rsync module parses and displays helpful error messages for common failures
- Supports bandwidth limiting, dry-run mode, and delete option
- Documentation includes automated sync setup via cron or systemd
- Comparison table between rsync and Syncthing included

---

## 2026-01-26 16:52 - Task 9.3

**Status**: pending → done
**Validation**:
- Added `enabled` field to SpokeConfig (boolean, default: true)
- Added `schedule` field for rsync cron scheduling
- Added `RsyncOptions` interface with bwLimit, delete, extraArgs, timeoutSeconds
- Added `rsyncOptions` field to SpokeConfig
- Updated getSessionDirs to only include enabled spokes
- Added getEnabledSpokes, getRsyncSpokes, getScheduledRsyncSpokes helper functions
- Updated runRsync to merge spoke.rsyncOptions with CLI options (CLI takes precedence)
- Updated formatSyncStatus to show disabled spokes with (disabled) marker
- Added validation: schedule and rsync_options rejected on non-rsync spokes
- Added validation: invalid bw_limit and timeout_seconds values
- Added 15 new unit tests covering all new configuration options
- Updated existing tests to include enabled field
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 836 passed, 4 skipped)
**Commit**: b9b2da7
**Notes**:
- Configuration now matches specs/sync-protocol.md spoke config spec
- Ready for Task 9.4 (Daemon watches synced directories)
- The schedule field enables spoke-specific rsync schedules
- rsyncOptions allows per-spoke customization of bandwidth, delete behavior, and timeout

---

## 2026-01-26 17:10 - Task 9.4

**Status**: pending → done
**Validation**:
- Added syncedStabilityThreshold to WatcherConfig (30s for synced vs 5s for local)
- Added spokePaths Set to track spoke directories in SessionWatcher
- Implemented addSpokePath(), isFromSpoke(), getStabilityThreshold(), getSpokePaths() methods
- Updated fromConfig() and startFromConfig() to track spoke paths from config
- Added 5 new tests for spoke path detection:
  - "should track enabled spoke paths"
  - "should identify sessions from spoke directories"
  - "should return appropriate stability thresholds"
  - "should use custom stability thresholds if configured"
  - "should watch both hub and spoke directories with startFromConfig" (integration test)
- Updated default stabilityThreshold from 2s to 5s per spec
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 844 passed, 4 skipped)
**Commit**: f6bcb93
**Notes**:
- The watcher now properly tracks which directories are from spokes
- Different stability thresholds allow for network sync delays on spoke sessions
- isFromSpoke() method enables differentiated handling downstream (e.g., in worker for computer field)
- Also included uncommitted Task 9.3 security additions (rsync extra_args validation)

---

## 2026-01-26 17:48 - Task 9.5

**Status**: pending → done
**Validation**:
- Added getComputerFromPath() helper in src/config/config.ts
- For spoke sessions, returns the spoke name from config
- For local sessions (hub), returns os.hostname()
- Uses proper path boundary checking (e.g., /synced/laptop doesn't match /synced/laptop-backup)
- Updated worker to use getComputerFromPath() instead of hardcoded os.hostname()
- Added 7 unit tests for getComputerFromPath() covering:
  - Local sessions → hostname
  - Spoke sessions → spoke name
  - Multiple spokes
  - Disabled spokes
  - Trailing slashes
  - Path boundary checking
  - Empty spokes
- Fixed watcher isFromSpoke() path boundary checking (uncommitted from 9.4)
- Added 2 tests for watcher path boundary edge cases
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 853 passed, 4 skipped)
**Commit**: cb3d0be
**Notes**:
- The computer field now correctly identifies which machine a session came from
- For local hub sessions: uses the hostname (e.g., "desktop")
- For synced spoke sessions: uses the spoke name from config (e.g., "laptop", "server")
- This enables filtering and grouping nodes by source computer in the UI
- Phase 9 (Multi-Computer Sync) is now complete

---

## 2026-01-26 18:25 - Task 10.1

**Status**: pending → done
**Validation**:
- Created InsightAggregator class that aggregates:
  - Model quirks from model_quirks table
  - Tool errors from tool_errors table
  - Lessons at model/tool/user levels from lessons table
  - Prompting wins/failures from node JSON files
- Added migration 007_aggregated_insights.sql with new table schema
- Added AggregatedInsight and related types to src/types/index.ts
- Added pattern-repository functions for querying insights:
  - listInsights with filtering by type, model, tool, frequency, confidence
  - getInsight, getInsightsByModel, countInsights, updateInsightPrompt
- Integrated InsightAggregator into scheduler's pattern aggregation job
- Added 7 tests for InsightAggregator covering all aggregation sources
- Added 11 tests for pattern-repository insight functions
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 880 passed, 4 skipped)
**Commit**: eb0ad98
**Notes**:
- InsightAggregator runs as part of the nightly pattern aggregation job
- Insights are stored with frequency, confidence, severity, and examples
- Ready for Task 10.2 (Generate model-specific prompt additions)
- The aggregated_insights table includes prompt_text and prompt_included fields for Phase 10.2+

---

## 2026-01-26 18:45 - Task 10.2

**Status**: pending → done
**Validation**:
- Created prompt-generator.ts with core functions:
  - generatePromptAdditions(): Generate PromptAddition objects from insights
  - formatModelSection(): Format quirks, wins, tool reminders as markdown
  - filterActionableInsights(): Filter by confidence/frequency thresholds
  - getModelDisplayName(): Human-readable "Google Gemini 3 Flash" from "google/gemini-3-flash"
  - generatePromptAdditionsFromDb(): Database integration wrapper
  - getPromptAdditionsForModel(): Get additions for specific model
  - updateInsightPromptTexts(): Store generated prompts back to database
  - formatPromptAdditionsDocument(): Combine all additions into markdown doc
- Added PromptAddition type to src/types/index.ts for shared use
- Added CLI commands:
  - pi-brain prompt-learning preview [--model X] [--json]: Preview generated prompts
  - pi-brain prompt-learning insights [--model X] [--type Y]: List aggregated insights
- Added 33 new tests:
  - 4 tests for getModelDisplayName
  - 3 tests for groupInsightsByModel
  - 5 tests for filterActionableInsights
  - 6 tests for formatModelSection
  - 6 tests for generatePromptAdditions
  - 3 tests for formatPromptAdditionsDocument
  - 3 tests for generatePromptAdditionsFromDb (database integration)
  - 2 tests for getPromptAdditionsForModel (database integration)
  - 1 test for updateInsightPromptTexts (database integration)
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 913 passed, 4 skipped)
**Commit**: 4150c0a
**Notes**:
- Prompt additions are generated per-model with three sections:
  - Known quirks to avoid (with workarounds)
  - Effective techniques (prompting wins)
  - Tool usage reminders (tool errors and failures)
- Insights require minimum confidence (0.5) and frequency (3) to be included
- Quirks additionally require a workaround to be actionable
- Ready for Task 10.3 (Implement prompt injection mechanism)

---

## 2026-01-26 18:55 - Task 10.3

**Status**: pending → done
**Validation**:
- Created prompt-injector.ts with two injection methods:
  - skill (recommended): Generate brain-insights skill in ~/skills/brain-insights/
  - agents_file: Modify AGENTS.md directly (not recommended, affects all sessions)
- Functions implemented:
  - generateBrainInsightsSkill(): Generate skill markdown from PromptAddition[]
  - writeBrainInsightsSkill(): Write skill to disk from database insights
  - generateModelSkill(): Generate skill for a specific model
  - updateAgentsFile(): Add/update pi-brain section in AGENTS.md
  - removeFromAgentsFile(): Remove pi-brain section from AGENTS.md
  - injectInsights(): Main injection function using configured method
  - removeInjectedInsights(): Remove injected insights
  - getInjectionStatus(): Check current injection status
- Added CLI commands:
  - pi-brain prompt-learning inject [--method skill|agents_file] [--min-confidence n] [--min-frequency n]
  - pi-brain prompt-learning remove [--method skill|agents_file]
  - pi-brain prompt-learning status
- Made agentsFilePath configurable for testing (avoid mocking os.homedir)
- 22 new tests covering all injection functions
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 935 passed, 4 skipped)
**Commit**: cfc0476
**Notes**:
- Default injection method is "skill" (recommended per spec)
- Skill is generated at ~/skills/brain-insights/SKILL.md
- Empty skill generated when no actionable insights meet thresholds (freq >= 5, conf >= 0.7)
- AGENTS.md injection uses markers for easy update/removal
- Ready for Task 10.4 (Feedback loop: quirk → prompt fix → measure improvement)

---

## 2026-01-26 19:06 - Task 10.4

**Status**: pending → done
**Validation**:
- Created migration 008_prompt_effectiveness.sql with schema for tracking
  prompt effectiveness (before/after occurrences, severity, improvement_pct)
- Added columns: id, insight_id, prompt_version, before/after_occurrences,
  before/after_severity, before/after_start/end, improvement_pct,
  statistically_significant, sessions_before/after, measured_at, timestamps
- Added foreign key constraint to aggregated_insights with cascading deletes
- Added 4 indexes: idx_effectiveness_insight, idx_effectiveness_measured_at,
  idx_effectiveness_significant, idx_effectiveness_improvement
- Added TypeScript types to src/types/index.ts:
  - DateRange: For before/after period specification
  - EffectivenessResult: For measureEffectiveness() function return value
  - PromptEffectiveness: Full database record type
- Added 5 new tests in database.test.ts:
  - creates prompt learning tables (aggregated_insights, prompt_effectiveness)
  - creates prompt_effectiveness table with correct columns (17 columns verified)
  - creates prompt_effectiveness indexes (4 indexes verified)
  - enforces foreign key on prompt_effectiveness to aggregated_insights
  - cascades deletes from aggregated_insights to prompt_effectiveness
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 940 passed, 4 skipped)
**Commit**: b30b56d
**Notes**:
- Table design follows specs/prompt-learning.md schema
- Sessions counts added for rate calculations (not in original spec but needed)
- Ready for Task 10.5 (Implement measureEffectiveness() function)

---

## 2026-01-26 19:45 - Task 10.5

**Status**: pending → done
**Validation**:
- Created effectiveness.ts with core measurement functions:
  - measureEffectiveness(): Compares occurrence rates before/after prompt was added
  - measureAndStoreEffectiveness(): Measures and persists result to prompt_effectiveness table
  - countSessions(): Counts unique sessions within a date range
  - countNodes(): Counts nodes within a date range
  - countOccurrences(): Counts insight occurrences by type (quirk, tool_error, lesson, win, failure)
  - calculateAverageSeverity(): Converts severity level to numeric value (0.0-1.0)
  - isStatisticallySignificant(): Simplified chi-square test for p < 0.05
  - getEffectivenessHistory(): Returns measurement history for an insight
  - getLatestEffectiveness(): Returns most recent measurement
  - getInsightsNeedingMeasurement(): Finds insights that need re-measurement
- Added migration 009_effectiveness_unique.sql for unique constraint on (insight_id, prompt_version)
- Updated database.test.ts to verify unique constraint
- Added 25 comprehensive tests covering all functions
- Exported new functions from prompt/index.ts
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 966 passed, 4 skipped)
**Commit**: c6e2b41
**Notes**:
- Occurrence counting varies by insight type:
  - quirk: Counts model_quirks rows matching pattern and model
  - tool_error: Counts tool_errors rows matching tool and model
  - lesson: Counts lessons rows matching pattern (model/tool/user levels)
  - win/failure: Reads node JSON files and counts prompting wins/failures
- Statistical significance requires minimum 10 sessions in each period
- Ready for Task 10.6 (Implement auto-disable for ineffective insights)

---

## 2026-01-26 21:14 - Task 11.1

**Status**: pending → done
**Validation**:
- Created signals.ts with friction signal detection functions:
  - countRephrasingCascades(): Detects 3+ consecutive user messages without tool call
  - countToolLoops(): Detects same tool error 3+ times (normalized comparison)
  - countContextChurn(): Detects high-frequency read/ls on different files
  - detectModelSwitch(): Detects when segment uses different model than previous
  - detectSilentTermination(): Detects session ending with unresolved error
  - extractManualFlags(): Extracts brain_flag custom entries
  - isAbandonedRestart(): Detects abandoned node followed by restart within 30 mins
  - calculateFrictionScore(): Computes weighted 0.0-1.0 friction score
- Added utility functions: getFilesTouched(), hasFileOverlap(), getPrimaryModel(), getSegmentTimestamp()
- Added types to src/types/index.ts:
  - FrictionSignals: rephrasingCount, contextChurnCount, abandonedRestart, toolLoopCount, modelSwitchFrom, silentTermination, score
  - DelightSignals: resilientRecovery, oneShotSuccess, explicitPraise, score
  - ManualFlag: type, message, timestamp
  - NodeSignals: friction, delight, manualFlags
  - Updated Node interface to include optional signals field
- 41 new tests covering all friction signal detection functions
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 1016 passed, 4 skipped)
**Commit**: 967c85f
**Notes**:
- Friction score weights: rephrasing=0.15 (cap 0.3), churn=0.1 (cap 0.2), toolLoop=0.2 (cap 0.4), abandonedRestart=0.3, modelSwitch=0.15, silentTermination=0.25
- Error messages are normalized (numbers→N, paths→PATH, strings→STR) for tool loop comparison
- Context churn threshold is 10 unique file reads/ls before counting as churn event
- Abandoned restart requires: outcome=abandoned, restart within 30 mins, file overlap >= 30%
- Ready for Task 11.2 (Delight signal detection)

---

## 2026-01-26 21:26 - Task 11.2

**Status**: pending → done
**Validation**:
- Created delight signal detection functions in src/parser/signals.ts:
  - detectResilientRecovery(): detects tool error → model retry → success (no user intervention)
  - detectOneShotSuccess(): detects 3+ tool calls with zero user corrections
  - detectExplicitPraise(): detects genuine praise (thanks, perfect, great, etc.) with sarcasm filtering
  - calculateDelightScore(): weighted score (resilient=0.4, one-shot=0.4, praise=0.3, cap at 1.0)
  - detectDelightSignals(): main entry point combining all signals
- Added 34 new tests in signals.test.ts covering:
  - Resilient recovery scenarios (6 tests)
  - One-shot success detection (5 tests)
  - Explicit praise detection (14 tests)
  - Score calculation (5 tests)
  - Combined signal detection (4 tests)
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 1059 passed, 4 skipped)
**Commit**: 26929d5
**Notes**:
- DelightSignals type already existed in src/types/index.ts from Task 11.1
- Detection logic handles edge cases:
  - User praise AFTER recovery doesnt count as intervention
  - Sarcastic phrases filtered (e.g., "great, another error")
  - Minimal acknowledgments (ok, yes) dont break one-shot success
  - Questions treated as corrections (indicate confusion)
- Ready for Task 11.3 (Update Node model to include signals)


---

## 2026-01-26 21:45 - Task 11.3

**Status**: pending → done
**Validation**:
- Added `signals?: NodeSignals` field to `NodeConversionContext` interface
- Updated `agentOutputToNode()` to spread signals into returned Node when provided
- Updated Worker to detect friction/delight signals from segment entries:
  - Uses `detectFrictionSignals()` with isLastSegment and wasResumed options
  - Uses `detectDelightSignals()` with outcome from agent analysis
  - Uses `extractManualFlags()` to capture user-flagged entries
- Added 2 new tests for signal inclusion in agentOutputToNode
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 1061 passed, 4 skipped)
**Commit**: 12fc8d9
**Notes**:
- Node.signals is optional - only included when signals are detected
- Signals are computed from raw session entries, not from LLM analysis
- The friction/delight detection functions were already implemented in Task 11.1/11.2
- This task integrates them into the actual node creation pipeline
- JSON node files now include signals field when created by worker
- Ready for Task 11.4 (/brain --flag manual notation command)

---

## 2026-01-26 21:53 - Task 11.4

**Status**: pending → done
**Validation**:
- Added `/brain --flag` command to brain-query extension for manual notation
- Supported syntax formats:
  - `/brain --flag <type> <message>` - standard form
  - `/brain -f <type> <message>` - short form
  - `/brain --flag:<type> <message>` - colon syntax
  - `/brain -f:<type> <message>` - short colon syntax
- Valid flag types: quirk, failure, win, note
- Flags written as `custom` entries with `customType: "brain_flag"` via `pi.appendEntry()`
- Entries are extracted by `extractManualFlags()` during daemon analysis (from Task 11.1)
- Added 13 new tests covering:
  - Flag recording with --flag and -f syntax
  - Colon syntax variants
  - All four flag types
  - Error handling for invalid types
  - Error handling for missing type/message
  - Distinction from query commands
  - Case-insensitive type matching
- Updated brain skill SKILL.md with flag usage documentation
- All lint checks pass (npm run check)
- All tests pass (npm test -- --run: 1074 passed, 4 skipped)
**Commit**: 6c1f169
**Notes**:
- The flag command integrates with existing signals infrastructure
- Flags are stored in Node.signals.manualFlags after daemon analysis
- Multiple spaces in messages are normalized to single spaces (by design)
- Ready for Task 11.5 (Facet discovery pipeline)

---

## 2026-01-26 22:10 - Task 11.5

**Status**: pending → done
**Validation**:
- Created database migration 010_clusters.sql with tables:
  - node_embeddings: Cached embeddings for nodes
  - clusters: Discovered clusters with name/description/status
  - cluster_nodes: Cluster membership with distance and representative flag
  - clustering_runs: Track clustering job executions
- Implemented facet discovery pipeline in src/daemon/facet-discovery.ts:
  - EmbeddingProvider interface with Ollama, OpenAI, and Mock implementations
  - K-means++ clustering algorithm
  - HDBSCAN-like density-based clustering (simplified)
  - FacetDiscovery class for running the pipeline
  - Embedding caching for efficiency
  - Cluster CRUD operations (getClusters, getClusterNodes, updateClusterStatus, etc.)
- Added cluster-related types to src/types/index.ts:
  - Cluster, ClusterNode, NodeEmbedding, ClusteringRun
  - EmbeddingConfig, ClusteringConfig, FacetDiscoveryResult
  - ClusterStatus, ClusterSignalType
- Added 34 tests in facet-discovery.test.ts covering:
  - Embedding provider creation and embedding generation
  - K-means clustering correctness
  - HDBSCAN clustering correctness
  - FacetDiscovery run, getClusters, getClusterNodes, updateClusterStatus
- All tests pass (1110 passed, 4 skipped)
- 9 lint violations for conditional expects in tests (deferred to Task 11.5a)
**Commit**: a9b949e
**Notes**:
- Signal-based filtering (friction/delight) deferred - requires adding signal columns to nodes table
- Task 11.5a created for lint fix (TODO-f8b10687)
- Task 11.6 will add LLM cluster analysis and naming
- Task 11.9 will add clustering to nightly scheduler
